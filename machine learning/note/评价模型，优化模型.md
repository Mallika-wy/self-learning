## Evaluating model

将一组数据分成三份，训练集、测试集、交叉验证集。训练集数据最多，大概占60%；测试集和交叉验证集较少。

针对一个问题，我们在选择模型的时候，会计算出各个模型的training error、cross validation error and test error。我们会选择具有最低交叉验证错误的模型，而$J_{test}$作为an estimate of the generalization error（泛化误差的估计值）。本质上就是确保test set中的数据是没被用于决策的，是独立的，这样可以确保得出的测试结果中公平公正的。

对于不同的模型， $J_{train}$、 $J_{test}$和$J_{cv}$都是不同的。

**对于linear regression：**

computer test error：
$$
J_{test}(\vec w,b)=\frac{1}{2m_{test}}[\sum_{i=1}^{m_{test}}(f_{\vec w,b}(\vec x_{test}^{(i)})-y_{test}^{(i)})^2]
$$
computer validation error：
$$
J_{cv}(\vec w,b)=\frac{1}{2m_{cv}}[\sum_{i=1}^{m_{cv}}(f_{\vec w,b}(\vec x_{cv}^{(i)})-y_{cv}^{(i)})^2]
$$
compute training error:
$$
J_{train}(\vec w,b)=\frac{1}{2m_{train}}[\sum_{i=1}^{m_{train}}(f_{\vec w,b}(\vec x_{train}^{(i)})-y_{train}^{(i)})^2]
$$
**对于classification problem：**

computer test error：
$$
J_{test}(\vec w,b)=-\frac{1}{m_{test}}\sum_{i=1}^{m_{test}}[y_{test}^{(i)}log(f_{\vec w,b}(\vec x_{test}^{(i)})+(1-y_{test}^{(i)})log(1-f_{\vec w,b}(\vec x_{test}^{(i)}))]
$$
compute validation error:
$$
J_{cv}(\vec w,b)=-\frac{1}{m_{cv}}\sum_{i=1}^{m_{cv}}[y_{cv}^{(i)}log(f_{\vec w,b}(\vec x_{cv}^{(i)})+(1-y_{cv}^{(i)})log(1-f_{\vec w,b}(\vec x_{cv}^{(i)}))]
$$
compute train error:
$$
J_{train}(\vec w,b)=-\frac{1}{m_{train}}\sum_{i=1}^{m_{train}}[y_{train}^{(i)}log(f_{\vec w,b}(\vec x_{train}^{(i)})+(1-y_{train}^{(i)})log(1-f_{\vec w,b}(\vec x_{train}^{(i)}))]
$$



### 两个指标 bias and variance

bias 偏差，指的是在训练集中模型与实际值之间的差距。

variance 方差，指的是训练集效果与交叉验证集效果之间的差距。

一般来说模型出问题会在这两个指标上体现：

- High bias（underfit）

  $J_{train}$ will be high  ($J_{train}\approx J_{cv}$)

- High variance(overfit)

  $J_{cv}>>J_{train}$ ($J_{train}$  may be be low)

- High bias and high variance

  $J_{train}$ will be high and $J_{cv}>>J_{train}$ 

  

### degree 对 $J_{cv}$和$J_{train}$的影响

![image-20240222134600066](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240222134600066.png)

随着拟合的多项式最高次数的增加，$J_{train}$会随之减小，$J_{cv}$会先减小在增大。当d很小的时候，会出现欠拟合的问题，当d很大的时候，会出现过拟合的问题，这就是模型不能很好适应validation set的原因也是$J_{cv}$先减小再增大的原因。只有不大也不小的d才会恰恰好好。

### regularization parameter $\lambda$对bias and variance的影响

![image-20240222141750004](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240222141750004.png)

随着$\lambda$的增大，$J_{cv}$是先减小后增大的，$J_{train}$是一直增大的。当我们已近选择了一个模型的时候，我们需要确定合适的正则化参数使得模型更加符合数据。

当$\lambda$过小，正则化不起作用，$J_{cv}$依旧很大；当$\lambda$过大，模型会变成一条平行于X轴的直线，会变得欠拟合，$J_{cv}$仍是很大。

随着$\lambda$的增大，成本函数会不可避免的增大，所以$J_{train}$会一直增大。

### Establish a baseline level of performance

如何判断$J_{train}$和$J_{cv}$是大还是小呢？

- Human level performance
- competing algorithms performance
- guess based on experience

如果$J_{train}$和baseline performance之间差距很大，就可一判定这个模型高偏差

如果$J_{train}$和$J_{cv}$之间差距很大，就可以判定这个模型高方差

### 学习曲线

**High bias：**

如果说学习曲线长这样子，说明模型具有高偏差，这个是模型没有拟合好，无论train set增加到多大，都无法解决。

![image-20240224095026744](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240224095026744.png)

**High variance：**

如果学习算法是高方差的话，可能$J_{train}$比人类水平都低，因为这个其几乎零差错。

对于高方差的算法，增大训练集对于优化模型有帮助。

![image-20240224095517887](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20240224095517887.png)

## Debugging a learning algorithm

### 解决high bias

1. try getting additional features
2. try adding polynomial features
3. try decreasing $\lambda$

### 解决high variance

1. get more training examples
2. try smaller sets of features
3. try increasing $\lambda$